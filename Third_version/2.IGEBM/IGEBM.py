# -*- coding: utf-8 -*-
"""thesis_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ae9LMYepeoSLMAXB4t7VRPflyadCnM3l

This code refer from Github URL: https://github.com/karimul/Riset-EBM
And Github URL: https://github.com/yilundu/improved_contrastive_divergence

My contribution is the function:
gen_sgld_image()
gen_mala_image()
gen_psgld_image()
And other slightly modification for successfully debugging.
"""

!pip install geomloss
!pip install torchmetrics[image]

from google.colab import drive
import os
drive.mount('/content/drive')

ROOT = "/content/drive/MyDrive/Colab Notebooks"
sample_dir = os.path.join(ROOT, 'thesis.mala.noinitial_final')
if not os.path.exists(sample_dir):
    os.makedirs(sample_dir)
os.chdir(sample_dir)

from easydict import EasyDict
from tqdm import tqdm
import time
import timeit
import os.path as osp
import pandas as pd
from PIL import Image
import pickle
from imageio import imread
import cv2
import scipy.spatial as ss

import torch.nn as nn
from torch.autograd import Variable
from torch.utils.data import Dataset
import torchvision
import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchvision.datasets import MNIST
from torch.nn import Dropout
from torch.optim import Adam, SGD
import torch.nn.functional as F
from torch.nn.utils import clip_grad_norm_
from torchvision import models
from torchmetrics import IS, FID, KID
from torch import autograd

import numpy as np
import random
import matplotlib.pyplot as plt
from scipy import linalg
from math import exp, log
from geomloss import SamplesLoss

from autograd.numpy import sqrt, sin, cos, exp, pi, prod
from autograd.numpy.random import normal
from collections import OrderedDict

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

flags = EasyDict()

# Configurations for distributed training
flags['slurm'] = False # whether we are on slurm
flags['repel_im'] = True # maximize entropy by repeling images from each other
flags['hmc'] = False # use the hamiltonian monte carlo sampler
flags['square_energy'] = False # make the energy square
flags['alias'] = False # make the energy square
flags['cpu'] = torch.device("cpu")
flags['gpu'] = torch.device("cuda:0")

flags['fid_path'] = './mnist_test.npz'
flags['batch_size'] = 128 #128 # batch size during training
flags['multiscale'] = True # A multiscale EBM
flags['self_attn'] = True #Use self attention in models
flags['sigmoid'] = False # Apply sigmoid on energy (can improve the stability)
flags['data_workers'] = 4 # Number of different data workers to load data in parallel
flags['buffer_size'] = 10000 # Size of inputs

# General Experiment Settings
flags['exp'] = 'default' #name of experiments
flags['log_interval'] = 20 #log outputs every so many batches
flags['save_interval'] = 100 # save outputs every so many batches
flags['test_interval'] = 100 # evaluate outputs every so many batches
flags['resume_iter'] = 0 #iteration to resume training from
flags['train'] = True # whether to train or test
flags['transform'] = True # apply data augmentation when sampling from the replay buffer
flags['kl'] = True # apply a KL term to loss
flags['entropy'] = 'kl' 
flags['cuda'] = True # move device on cuda
flags['epoch_num'] = 100 # Number of Epochs to train on
flags['ensembles'] = 1 #Number of ensembles to train models with
flags['lr'] = 2e-4 #Learning for training
flags['kl_coeff'] = 1.0 #coefficient for kl

# EBM Specific Experiments Settings
flags['objective'] = 'cd' #use the cd objective

# Setting for MCMC sampling
flags['num_steps'] = 60 # Steps of gradient descent for training
flags['step_lr'] = 100 # Size of steps for gradient descent
flags['replay_batch'] = True # Use MCMC chains initialized from a replay buffer.
flags['reservoir'] = False # Use a reservoir of past entires
flags['noise_scale'] = 1. # Relative amount of noise for MCMC
flags['init_noise'] = 0.1
flags['momentum'] = 0.9
flags['eps'] = 1e-6
flags['step_size'] = 10

# Architecture Settings
flags['filter_dim'] = 64 #64 #number of filters for conv nets
flags['im_size'] = 32 #32 #size of images
flags['spec_norm'] = False #Whether to use spectral normalization on weights
flags['norm'] = True #Use group norm in models norm in models

# Conditional settings

flags['cond'] = False #conditional generation with the model
flags['all_step'] = False #backprop through all langevin steps
flags['log_grad'] = False #log the gradient norm of the kl term
flags['cond_idx'] = 0 #conditioned index
flags['save'] = 0 
flags['itr'] = 0 #for save plot

#for testing the new sampling methods.
flags['tem'] = 10 
flags['tempering'] = False 
flags['Lambda'] = 1
flags['sampler'] = 'mala' # sgld psgld mala
flags['dataset'] = 'cifar10' # cifar10 or cats or mnist or svhn
flags['anneal'] = False # Decrease noise over Langevin steps
flags['initial'] = False
flags['initial_batch'] = 110

sample_method = []



writer = SummaryWriter(comment="_{sampler}_{entropy}_{dataset}".format(dataset=flags.dataset, entropy=flags.entropy, sampler=flags.sampler))

inception = IS().to(flags.gpu, non_blocking=True)
fid = FID(feature=2048).to(flags.gpu, non_blocking=True)

def swish(x):
    return x * torch.sigmoid(x)

class WSConv2d(nn.Conv2d):

    def __init__(self, in_channels, out_channels, kernel_size, stride=1,
                 padding=0, dilation=1, groups=1, bias=True):
        super(WSConv2d, self).__init__(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias)

    def forward(self, x):
        weight = self.weight
        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,
                                  keepdim=True).mean(dim=3, keepdim=True)
        weight = weight - weight_mean
        std = weight.view(weight.size(0), -1).std(dim=1).view(-1, 1, 1, 1) + 1e-5
        weight = weight / std.expand_as(weight)
        return F.conv2d(x, weight, self.bias, self.stride,
                        self.padding, self.dilation, self.groups)

def compress_x_mod(x_mod):
    x_mod = (255 * np.clip(x_mod, 0, 1)).astype(np.uint8)
    return x_mod

def decompress_x_mod(x_mod):
    x_mod = x_mod / 256  + \
        np.random.uniform(0, 1 / 256, x_mod.shape)
    return x_mod

class Downsample(nn.Module):
    def __init__(self, pad_type='reflect', filt_size=3, stride=2, channels=None, pad_off=0):
        super(Downsample, self).__init__()
        self.filt_size = filt_size
        self.pad_off = pad_off
        self.pad_sizes = [int(1.*(filt_size-1)/2), int(np.ceil(1.*(filt_size-1)/2)), int(1.*(filt_size-1)/2), int(np.ceil(1.*(filt_size-1)/2))]
        self.pad_sizes = [pad_size+pad_off for pad_size in self.pad_sizes]
        self.stride = stride
        self.off = int((self.stride-1)/2.)
        self.channels = channels

        if(self.filt_size==1):
            a = np.array([1.,])
        elif(self.filt_size==2):
            a = np.array([1., 1.])
        elif(self.filt_size==3):
            a = np.array([1., 2., 1.])
        elif(self.filt_size==4):
            a = np.array([1., 3., 3., 1.])
        elif(self.filt_size==5):
            a = np.array([1., 4., 6., 4., 1.])
        elif(self.filt_size==6):
            a = np.array([1., 5., 10., 10., 5., 1.])
        elif(self.filt_size==7):
            a = np.array([1., 6., 15., 20., 15., 6., 1.])

        filt = torch.Tensor(a[:,None]*a[None,:])
        filt = filt/torch.sum(filt)
        self.register_buffer('filt', filt[None,None,:,:].repeat((self.channels,1,1,1)))

        self.pad = get_pad_layer(pad_type)(self.pad_sizes)

    def forward(self, inp):
        if(self.filt_size==1):
            if(self.pad_off==0):
                return inp[:,:,::self.stride,::self.stride]
            else:
                return self.pad(inp)[:,:,::self.stride,::self.stride]
        else:
            return F.conv2d(self.pad(inp), self.filt, stride=self.stride, groups=inp.shape[1])

def get_pad_layer(pad_type):
    if(pad_type in ['refl','reflect']):
        PadLayer = nn.ReflectionPad2d
    elif(pad_type in ['repl','replicate']):
        PadLayer = nn.ReplicationPad2d
    elif(pad_type=='zero'):
        PadLayer = nn.ZeroPad2d
    else:
        print('Pad type [%s] not recognized'%pad_type)
    return PadLayer

class Self_Attn(nn.Module):
    """ Self attention Layer"""
    def __init__(self,in_dim,activation):
        super(Self_Attn,self).__init__()
        self.chanel_in = in_dim
        self.activation = activation

        self.query_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)
        self.key_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim//8 , kernel_size= 1)
        self.value_conv = nn.Conv2d(in_channels = in_dim , out_channels = in_dim , kernel_size= 1)
        self.gamma = nn.Parameter(torch.zeros(1))

        self.softmax  = nn.Softmax(dim=-1) #

    def forward(self,x):
        """
            inputs :
                x : input feature maps( B X C X W X H)
            returns :
                out : self attention value + input feature
                attention: B X N X N (N is Width*Height)
        """
        m_batchsize,C,width ,height = x.size()
        proj_query  = self.query_conv(x).view(m_batchsize,-1,width*height).permute(0,2,1) # B X CX(N)
        proj_key =  self.key_conv(x).view(m_batchsize,-1,width*height) # B X C x (*W*H)
        energy =  torch.bmm(proj_query,proj_key) # transpose check
        attention = self.softmax(energy) # BX (N) X (N) 
        proj_value = self.value_conv(x).view(m_batchsize,-1,width*height) # B X C X N

        out = torch.bmm(proj_value,attention.permute(0,2,1) )
        out = out.view(m_batchsize,C,width,height)

        out = self.gamma*out + x
        return out,attention

class CondResBlock(nn.Module):
    def __init__(self, args, downsample=True, rescale=True, filters=64, latent_dim=64, im_size=64, classes=512, norm=True, spec_norm=False):
        super(CondResBlock, self).__init__()

        self.filters = filters
        self.latent_dim = latent_dim
        self.im_size = im_size
        self.downsample = downsample

        if filters <= 128:
            self.bn1 = nn.InstanceNorm2d(filters, affine=True)
        else:
            self.bn1 = nn.GroupNorm(32, filters)

        if not norm:
            self.bn1 = None

        self.args = args

        if spec_norm:
            self.conv1 = spectral_norm(nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1))
        else:
            self.conv1 = WSConv2d(filters, filters, kernel_size=3, stride=1, padding=1)

        if filters <= 128:
            self.bn2 = nn.InstanceNorm2d(filters, affine=True)
        else:
            self.bn2 = nn.GroupNorm(32, filters, affine=True)

        if not norm:
            self.bn2 = None

        if spec_norm:
            self.conv2 = spectral_norm(nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1))
        else:
            self.conv2 = WSConv2d(filters, filters, kernel_size=3, stride=1, padding=1)

        self.dropout = Dropout(0.2)

        # Upscale to an mask of image
        self.latent_map = nn.Linear(classes, 2*filters)
        self.latent_map_2 = nn.Linear(classes, 2*filters)

        self.relu = torch.nn.ReLU(inplace=True)
        self.act = swish

        # Upscale to mask of image
        if downsample:
            if rescale:
                self.conv_downsample = nn.Conv2d(filters, 2 * filters, kernel_size=3, stride=1, padding=1)

                if args.alias:
                    self.avg_pool = Downsample(channels=2*filters)
                else:
                    self.avg_pool = nn.AvgPool2d(3, stride=2, padding=1)
            else:
                self.conv_downsample = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1)

                if args.alias:
                    self.avg_pool = Downsample(channels=filters)
                else:
                    self.avg_pool = nn.AvgPool2d(3, stride=2, padding=1)


    def forward(self, x, y):
        x_orig = x

        if y is not None:
            latent_map = self.latent_map(y).view(-1, 2*self.filters, 1, 1)

            gain = latent_map[:, :self.filters]
            bias = latent_map[:, self.filters:]

        x = self.conv1(x)

        if self.bn1 is not None:
            x = self.bn1(x)

        if y is not None:
            x = gain * x + bias

        x = self.act(x)

        if y is not None:
            latent_map = self.latent_map_2(y).view(-1, 2*self.filters, 1, 1)
            gain = latent_map[:, :self.filters]
            bias = latent_map[:, self.filters:]

        x = self.conv2(x)

        if self.bn2 is not None:
            x = self.bn2(x)

        if y is not None:
            x = gain * x + bias

        x = self.act(x)

        x_out = x

        if self.downsample:
            x_out = self.conv_downsample(x_out)
            x_out = self.act(self.avg_pool(x_out))

        return x_out

class MNISTModel(nn.Module):
    def __init__(self, args):
        super(MNISTModel, self).__init__()
        self.act = swish
        # self.relu = torch.nn.ReLU(inplace=True)

        self.args = args
        self.filter_dim = args.filter_dim
        self.init_main_model()
        self.init_label_map()
        self.filter_dim = args.filter_dim

        # self.act = self.relu
        self.cond = args.cond
        self.sigmoid = args.sigmoid


    def init_main_model(self):
        args = self.args
        filter_dim = self.filter_dim
        im_size = 28
        self.conv1 = nn.Conv2d(1, filter_dim, kernel_size=3, stride=1, padding=1)
        self.res1 = CondResBlock(args, filters=filter_dim, latent_dim=1, im_size=im_size)
        self.res2 = CondResBlock(args, filters=2*filter_dim, latent_dim=1, im_size=im_size)

        self.res3 = CondResBlock(args, filters=4*filter_dim, latent_dim=1, im_size=im_size)
        self.energy_map = nn.Linear(filter_dim*8, 1)


    def init_label_map(self):
        args = self.args

        self.map_fc1 = nn.Linear(10, 256)
        self.map_fc2 = nn.Linear(256, 256)

    def main_model(self, x, latent):
        x = x.view(-1, 1, 28, 28)
        x = self.act(self.conv1(x))
        x = self.res1(x, latent)
        x = self.res2(x, latent)
        x = self.res3(x, latent)
        x = self.act(x)
        x = x.mean(dim=2).mean(dim=2)
        energy = self.energy_map(x)

        return energy

    def label_map(self, latent):
        x = self.act(self.map_fc1(latent))
        x = self.map_fc2(x)

        return x

    def forward(self, x, latent):
        args = self.args
        x = x.view(x.size(0), -1)

        if self.cond:
            latent = self.label_map(latent)
        else:
            latent = None

        energy = self.main_model(x, latent)

        return energy

class ResNetModel(nn.Module):
    def __init__(self, args):
        super(ResNetModel, self).__init__()
        self.act = swish

        self.args = args
        self.spec_norm = args.spec_norm
        self.norm = args.norm
        self.init_main_model()

        if args.multiscale:
            self.init_mid_model()
            self.init_small_model()

        self.relu = torch.nn.ReLU(inplace=True)
        self.downsample = Downsample(channels=3)

        self.cond = args.cond

    def init_main_model(self):
        args = self.args
        filter_dim = args.filter_dim
        latent_dim = args.filter_dim
        im_size = args.im_size

        self.conv1 = nn.Conv2d(3, filter_dim, kernel_size=3, stride=1, padding=1)
        self.res_1a = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.res_1b = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=False, spec_norm=self.spec_norm, norm=self.norm)

        self.res_2a = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.res_2b = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=True, spec_norm=self.spec_norm, norm=self.norm)

        self.res_3a = CondResBlock(args, filters=2*filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.res_3b = CondResBlock(args, filters=2*filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=True, spec_norm=self.spec_norm, norm=self.norm)

        self.res_4a = CondResBlock(args, filters=4*filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.res_4b = CondResBlock(args, filters=4*filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=True, spec_norm=self.spec_norm, norm=self.norm)

        self.self_attn = Self_Attn(2 * filter_dim, self.act)

        self.energy_map = nn.Linear(filter_dim*8, 1)

    def init_mid_model(self):
        args = self.args
        filter_dim = args.filter_dim
        latent_dim = args.filter_dim
        im_size = args.im_size

        self.mid_conv1 = nn.Conv2d(3, filter_dim, kernel_size=3, stride=1, padding=1)
        self.mid_res_1a = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.mid_res_1b = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=False, spec_norm=self.spec_norm, norm=self.norm)

        self.mid_res_2a = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.mid_res_2b = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=True, spec_norm=self.spec_norm, norm=self.norm)

        self.mid_res_3a = CondResBlock(args, filters=2*filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.mid_res_3b = CondResBlock(args, filters=2*filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=True, spec_norm=self.spec_norm, norm=self.norm)

        self.mid_energy_map = nn.Linear(filter_dim*4, 1)
        self.avg_pool = Downsample(channels=3)

    def init_small_model(self):
        args = self.args
        filter_dim = args.filter_dim
        latent_dim = args.filter_dim
        im_size = args.im_size

        self.small_conv1 = nn.Conv2d(3, filter_dim, kernel_size=3, stride=1, padding=1)
        self.small_res_1a = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.small_res_1b = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=False, spec_norm=self.spec_norm, norm=self.norm)

        self.small_res_2a = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, downsample=False, spec_norm=self.spec_norm, norm=self.norm)
        self.small_res_2b = CondResBlock(args, filters=filter_dim, latent_dim=latent_dim, im_size=im_size, rescale=True, spec_norm=self.spec_norm, norm=self.norm)

        self.small_energy_map = nn.Linear(filter_dim*2, 1)

    def main_model(self, x, latent, compute_feat=False):
        x = self.act(self.conv1(x))

        x = self.res_1a(x, latent)
        x = self.res_1b(x, latent)

        x = self.res_2a(x, latent)
        x = self.res_2b(x, latent)

        if self.args.self_attn:
            x, _ = self.self_attn(x)

        x = self.res_3a(x, latent)
        x = self.res_3b(x, latent)

        x = self.res_4a(x, latent)
        x = self.res_4b(x, latent)
        x = self.act(x)

        x = x.mean(dim=2).mean(dim=2)

        if compute_feat:
            return x

        x = x.view(x.size(0), -1)
        energy = self.energy_map(x)

        if self.args.square_energy:
            energy = torch.pow(energy, 2)

        if self.args.sigmoid:
            energy = F.sigmoid(energy)

        return energy

    def mid_model(self, x, latent):
        x = F.avg_pool2d(x, 3, stride=2, padding=1)

        x = self.act(self.mid_conv1(x))

        x = self.mid_res_1a(x, latent)
        x = self.mid_res_1b(x, latent)

        x = self.mid_res_2a(x, latent)
        x = self.mid_res_2b(x, latent)

        x = self.mid_res_3a(x, latent)
        x = self.mid_res_3b(x, latent)
        x = self.act(x)

        x = x.mean(dim=2).mean(dim=2)

        x = x.view(x.size(0), -1)
        energy = self.mid_energy_map(x)

        if self.args.square_energy:
            energy = torch.pow(energy, 2)

        if self.args.sigmoid:
            energy = F.sigmoid(energy)

        return energy

    def small_model(self, x, latent):
        x = F.avg_pool2d(x, 3, stride=2, padding=1)
        x = F.avg_pool2d(x, 3, stride=2, padding=1)

        x = self.act(self.small_conv1(x))

        x = self.small_res_1a(x, latent)
        x = self.small_res_1b(x, latent)

        x = self.small_res_2a(x, latent)
        x = self.small_res_2b(x, latent)
        x = self.act(x)

        x = x.mean(dim=2).mean(dim=2)

        x = x.view(x.size(0), -1)
        energy = self.small_energy_map(x)

        if self.args.square_energy:
            energy = torch.pow(energy, 2)

        if self.args.sigmoid:
            energy = F.sigmoid(energy)

        return energy

    def forward(self, x, latent):
        args = self.args

        if self.cond:
            latent = self.label_map(latent)
        else:
            latent = None

        energy = self.main_model(x, latent)

        if args.multiscale:
            large_energy = energy
            mid_energy = self.mid_model(x, latent)
            small_energy = self.small_model(x, latent)

            # Add a seperate energy penalizing the different energies from each model
            energy = torch.cat([small_energy, mid_energy, large_energy], dim=-1)

        return energy

    def compute_feat(self, x, latent):
        return self.main_model(x, None, compute_feat=True)

class ReplayBuffer(object):
    def __init__(self, size, transform, dataset):
        """Create Replay buffer.
        Parameters
        ----------
        size: int
            Max number of transitions to store in the buffer. When the buffer
            overflows the old memories are dropped.
        """
        self._storage = []
        self._maxsize = size
        self._next_idx = 0

        def get_color_distortion(s=1.0):
        # s is the strength of color distortion.
            color_jitter = transforms.ColorJitter(0.8*s, 0.8*s, 0.8*s, 0.4*s)
            rnd_color_jitter = transforms.RandomApply([color_jitter], p=0.8)
            rnd_gray = transforms.RandomGrayscale(p=0.2)
            color_distort = transforms.Compose([
                rnd_color_jitter,
                rnd_gray])
            return color_distort

        color_transform = get_color_distortion()

        if dataset in ("cifar10", "cats", "svhn"):
            im_size = 32
        elif dataset == "mnist":
            im_size = 28
        else:
            assert False

        self.dataset = dataset
        if transform:
            if dataset in ("cifar10", "cats", "svhn"):
                self.transform = transforms.Compose([transforms.RandomResizedCrop(im_size, scale=(0.08, 1.0)), transforms.RandomHorizontalFlip(), color_transform, transforms.ToTensor()])
            elif dataset == "mnist":
                self.transform = None
            else:
                assert False
        else:
            self.transform = None

    def __len__(self):
        return len(self._storage)

    def add(self, ims):
        batch_size = ims.shape[0]
        if self._next_idx >= len(self._storage):
            self._storage.extend(list(ims))
        else:
            if batch_size + self._next_idx < self._maxsize:
                self._storage[self._next_idx:self._next_idx +
                              batch_size] = list(ims)
            else:
                split_idx = self._maxsize - self._next_idx
                self._storage[self._next_idx:] = list(ims)[:split_idx]
                self._storage[:batch_size - split_idx] = list(ims)[split_idx:]
        self._next_idx = (self._next_idx + ims.shape[0]) % self._maxsize

    def _encode_sample(self, idxes, no_transform=False, downsample=False):
        ims = []
        for i in idxes:
            im = self._storage[i]

            if self.dataset != "mnist":
                if (self.transform is not None) and (not no_transform):
                    im = im.transpose((1, 2, 0))
                    im = np.array(self.transform(Image.fromarray(np.array(im))))

                # if downsample and (self.dataset in ["celeba", "object", "imagenet"]):
                #     im = im[:, ::4, ::4]

            im = im * 255
            ims.append(im)
        return np.array(ims)

    def sample(self, batch_size, no_transform=False, downsample=False):
        """Sample a batch of experiences.
        Parameters
        ----------
        batch_size: int
            How many transitions to sample.
        Returns
        -------
        obs_batch: np.array
            batch of observations
        act_batch: np.array
            batch of actions executed given obs_batch
        rew_batch: np.array
            rewards received as results of executing act_batch
        next_obs_batch: np.array
            next set of observations seen after executing act_batch
        done_mask: np.array
            done_mask[i] = 1 if executing act_batch[i] resulted in
            the end of an episode and 0 otherwise.
        """
        idxes = [random.randint(0, len(self._storage) - 1)
                 for _ in range(batch_size)]
        return self._encode_sample(idxes, no_transform=no_transform, downsample=downsample), idxes

    def set_elms(self, data, idxes):
        if len(self._storage) < self._maxsize:
            self.add(data)
        else:
            for i, ix in enumerate(idxes):
                self._storage[ix] = data[i]

"""# Data sets """

class Mnist(Dataset):
    def __init__(
            self,
            
            train=True,
            full=False,
            augment=False,
            noise=True,
            rescale=1.0):
        self.data = torchvision.datasets.MNIST(
            "./data/mnist",
            transform=transforms.ToTensor(),
            download=True, train=train)
        self.labels = np.eye(10)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        im, label = self.data[index]
        label = self.labels[label]
        im = im.squeeze()
        im = im.numpy() / 256 * 255 + np.random.uniform(0, 1. / 256, (28, 28))
        im = np.clip(im, 0, 1)
        s = 28
        im_corrupt = np.random.uniform(0, 1, (s, s, 1))
        im = im[:, :, None]


        return torch.Tensor(im_corrupt), torch.Tensor(im), label

class Cifar10(Dataset):
    def __init__(
            self,
            FLAGS,
            train=True,
            full=False,
            augment=False,
            noise=True,
            rescale=1.0):

        if augment:
            transform_list = [
                torchvision.transforms.RandomCrop(32, padding=4),
                torchvision.transforms.RandomHorizontalFlip(),
                torchvision.transforms.ToTensor(),
            ]

            transform = transforms.Compose(transform_list)
        else:
            transform = transforms.ToTensor()

        self.full = full
        self.data = torchvision.datasets.CIFAR10(
            "./data/cifar10",
            transform=transform,
            train=train,
            download=True)
        self.test_data = torchvision.datasets.CIFAR10(
            "./data/cifar10",
            transform=transform,
            train=False,
            download=True)
        self.one_hot_map = np.eye(10)
        self.noise = noise
        self.rescale = rescale
        self.FLAGS = FLAGS

    def __len__(self):

        if self.full:
            return len(self.data) + len(self.test_data)
        else:
            return len(self.data)

    def __getitem__(self, index):
        FLAGS = self.FLAGS
        if self.full:
            if index >= len(self.data):
                im, label = self.test_data[index - len(self.data)]
            else:
                im, label = self.data[index]
        else:
            im, label = self.data[index]

        im = np.transpose(im, (1, 2, 0)).numpy()
        image_size = 32
        label = self.one_hot_map[label]

        im = im * 255 / 256

        im = im * self.rescale + \
            np.random.uniform(0, 1 / 256., im.shape)

        # np.random.seed((index + int(time.time() * 1e7)) % 2**32)

        im_corrupt = np.random.uniform(
            0.0, self.rescale, (image_size, image_size, 3))

        return torch.Tensor(im_corrupt), torch.Tensor(im), label

class Cats(Dataset):
    def __init__(
            self,
            augment=False,
            noise=True,
            rescale=1.0):

        if augment:
            transform_list = [
                torchvision.transforms.RandomCrop(32, padding=4),
                torchvision.transforms.RandomHorizontalFlip(),
                torchvision.transforms.ToTensor(),
            ]

            transform = transforms.Compose(transform_list)
        else:
            # transform = transforms.ToTensor()
            transform = transforms.Compose([
                # resize
                transforms.Resize(32),
                # center-crop
                transforms.CenterCrop(32),
                # to-tensor
                transforms.ToTensor()
            ])

        self.data = torchvision.datasets.ImageFolder('/content/cats', transform = transform)
        self.one_hot_map = np.eye(10)
        self.noise = noise
        self.rescale = rescale

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):        
        im, label = self.data[index]

        im = np.transpose(im, (1, 2, 0)).numpy()
        image_size = 32
        label = self.one_hot_map[label]

        im = im * 255 / 256

        im = im * self.rescale + \
            np.random.uniform(0, 1 / 256., im.shape)

        im_corrupt = np.random.uniform(
            0.0, self.rescale, (image_size, image_size, 3))

        return torch.Tensor(im_corrupt), torch.Tensor(im), label

class Svhn(Dataset):
    def __init__(self, train=True, augment=False):

        transform = transforms.ToTensor()

        if train:
            split = 'train'
        else:
            split = 'test'

        self.data = torchvision.datasets.SVHN("./data/svhn", transform=transform, download=True, split = split)
        self.one_hot_map = np.eye(10)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        im, label = self.data[index]

        im = np.transpose(im, (1, 2, 0)).numpy()
        image_size = 32
        label = self.one_hot_map[label]
        im = im * 255 / 256.
        im = im + np.random.uniform(0, 1 / 256, im.shape)

        im_corrupt = np.random.uniform(
            0.0, 1.0, (image_size, image_size, 3))

        return torch.Tensor(im_corrupt), torch.Tensor(im), label

def rescale_im(image):
    image = np.clip(image, 0, 1)
    return (np.clip(image * 256, 0, 255)).astype(np.uint8)

"""My contribution1:"""

def gen_sgld_image(label, FLAGS, model, im_neg, num_steps, sample=False, test = False):
    im_noise = torch.randn_like(im_neg).detach()

    im_negs_samples = []

    list_me = []
    q_list = []
    energy_diff_list = []
    move_list = []
    grad_list = []

    all_sample = []
    energy_list = []

    x_grad = 0
    ra = 0

    for i in range(num_steps):
        im_noise.normal_()

        if FLAGS.anneal:
            im_neg = im_neg + 0.001 * (num_steps - i - 1) / num_steps * im_noise
        else:
            im_neg = im_neg + 0.001 * im_noise

        im_neg.requires_grad_(requires_grad=True)
        energy = model.forward(im_neg, label)

        if FLAGS.all_step:
            im_grad = torch.autograd.grad([energy.sum()], [im_neg], create_graph=True)[0]
        else:
            im_grad = torch.autograd.grad([energy.sum()], [im_neg])[0]

        if i == num_steps - 1:
            im_neg_orig = im_neg
            im_neg = im_neg - FLAGS.step_lr * im_grad

            if test is True:
                im_neg_orig = im_neg
                log_xnew_x, log_x_xnew, out_x, out_xnew, neg_new_img, grad = calculate_mala(model, im_neg, label, im_noise, FLAGS.step_lr)
                im_neg = neg_new_img

                log_alpha = out_x - out_xnew + log_x_xnew - log_xnew_x
                
                square = ((neg_new_img-im_neg_orig) ** 1).sum(dim=tuple(range(1, (neg_new_img-im_neg_orig).ndim)))
                move_dis = (square ** (1)).mean()

                alpha = torch.exp(torch.clamp_max(log_alpha, 0))
                mask = torch.rand(im_neg.shape[0], device=alpha.device)
                mask.unsqueeze_(dim=-1)
                a = mask < alpha

                while len(a.shape) < len(im_neg.shape):
                    a.unsqueeze_(dim=-1)

                me = torch.mean(a.float()).float().item()

                ra += me
                move_list.append(move_dis.item())
                energy_diff_list.append((out_x - out_xnew).mean().item())
                q_list.append((log_x_xnew - log_xnew_x).mean().item())
                grad_list.append(grad.mean().item())
                list_me.append(me)

            if FLAGS.dataset in ("cifar10", "cats", "svhn"):
                n = 128
            elif FLAGS.dataset == "mnist":
                n = 128
            
            im_neg_kl = im_neg_orig[:n]
            if sample:
                pass
            else:
                energy = model.forward(im_neg_kl, label)
                im_grad = torch.autograd.grad([energy.sum()], [im_neg_kl], create_graph=True)[0]

            im_neg_kl = im_neg_kl - FLAGS.step_lr * im_grad[:n]
            im_neg_kl = torch.clamp(im_neg_kl, 0, 1)
        else:
            im_neg = im_neg - FLAGS.step_lr * im_grad
            
            if test == True:
                im_neg_orig = im_neg
                log_xnew_x, log_x_xnew, out_x, out_xnew, neg_new_img, grad = calculate_mala(model, im_neg_orig, label, im_noise, FLAGS.step_lr)

                log_alpha = out_x - out_xnew + log_x_xnew - log_xnew_x

                square = ((neg_new_img-im_neg_orig) ** 1).sum(dim=tuple(range(1, (neg_new_img-im_neg_orig).ndim)))
                move_dis = (square ** (1)).mean()

                alpha = torch.exp(torch.clamp_max(log_alpha, 0))
                mask = torch.rand(im_neg.shape[0], device=alpha.device)
                mask.unsqueeze_(dim=-1)
                a = mask < alpha

                while len(a.shape) < len(im_neg.shape):
                    a.unsqueeze_(dim=-1)

                me = torch.mean(a.float()).float().item()

                ra += me
                move_list.append(move_dis.item())
                energy_diff_list.append((out_x - out_xnew).mean().item())
                q_list.append((log_x_xnew - log_xnew_x).mean().item())
                grad_list.append(grad.mean().item())
                list_me.append(me)

        im_neg = im_neg.detach()

        if sample:
            im_negs_samples.append(im_neg)

        im_neg = torch.clamp(im_neg, 0, 1)

    if test == True:
            
            sample_method.append(ra/num_steps)
            
            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,energy_diff_list)        
            plt.xlabel('Steps in chain')
            plt.ylabel('Energy difference')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"sgld_Energy difference")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,list_me)     
            plt.xlabel('Steps in chain')
            plt.ylabel('AC-ratio')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"sgld_Accept")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,move_list)   
            plt.xlabel('Steps in chain')
            plt.ylabel('Transition Distance')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"sgld_Distance")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,q_list)
            plt.xlabel('Steps in chain')
            plt.ylabel('q(X|X`) Difference')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"sgld_QDifference")
            plt.close(0)


            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,grad_list)
            plt.xlabel('Steps in chain')
            plt.ylabel('Gradient')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+ "sgld_Gradient_energy")
            plt.close(0)
    if sample:
        return im_neg, im_neg_kl, im_negs_samples, np.abs(im_grad.detach().cpu().numpy()).mean()
    else:
        return im_neg, im_neg_kl, np.abs(im_grad.detach().cpu().numpy()).mean()

"""My contribution2:"""

def calculate_mala(Energy, neg_img, neg_id, noise, stepsize, no_acc = False, tem = 1.0, variance = 0):
    #first 
    out_x = Energy(neg_img,neg_id)/tem
    grad_1 = autograd.grad(out_x.sum(), neg_img, only_inputs=True)[0]
    dynamics = -stepsize * grad_1 + noise
    neg_img_ = neg_img + dynamics

    if variance == 0:
        v = (-4 * stepsize)
    else:
        v = variance

    xnew_x = 1 / v * torch.sum(((neg_img_ - neg_img + stepsize * grad_1) ** 2), dim=[1,2,3])
    xnew_x.unsqueeze_(dim=-1)

    #second
    neg_img_.requires_grad_(True)
    if neg_img_.grad is not None:
        neg_img_.grad.data.zero_()

    out_xnew = Energy(neg_img_,neg_id)/tem
    grad_2 = autograd.grad(out_xnew.sum(), neg_img_, only_inputs=True)[0]

    x_xnew = 1 / v * torch.sum(((neg_img - neg_img_ + stepsize * grad_2) ** 2), dim=[1,2,3])
    x_xnew.unsqueeze_(dim=-1)

    return xnew_x, x_xnew, out_x, out_xnew, neg_img_, grad_1

def gen_mala_image(label, FLAGS, model, im_neg, num_steps, sample=False, test = False):
    im_noise = torch.randn_like(im_neg).detach()

    im_negs_samples = []

    list_me = []
    q_list = []
    energy_diff_list = []
    move_list = []
    grad_list = []

    all_sample = []
    energy_list = []

    x_grad = 0
    ra = 0

    tem = 1

    for i in range(num_steps):
        im_noise.normal_()

        if FLAGS.anneal:
            im_neg = im_neg + 0.001 * (num_steps - i - 1) / num_steps * im_noise
        else:
            im_neg = im_neg + 0.001 * im_noise

        im_neg.requires_grad_(requires_grad=True)

        if i == num_steps - 1:
            im_neg_orig = im_neg
            log_xnew_x, log_x_xnew, out_x, out_xnew, neg_new_img, grad = calculate_mala(model, im_neg, label, im_noise, FLAGS.step_lr, tem = tem)
            log_alpha = out_x - out_xnew + log_x_xnew - log_xnew_x

            alpha = torch.exp(torch.clamp_max(log_alpha, 0))
            mask = torch.rand(im_neg.shape[0], device=alpha.device)
            mask.unsqueeze_(dim=-1)
            a = mask < alpha

            while len(a.shape) < len(im_neg.shape):
                a.unsqueeze_(dim=-1)

            me = torch.mean(a.float()).float().item()
            
            result = torch.where(a, neg_new_img, im_neg)
            im_neg = result

            square = ((im_neg-im_neg_orig) ** 1).sum(dim=tuple(range(1, (im_neg-im_neg_orig).ndim)))
            move_dis = (square ** (1)).mean()

            if FLAGS.tempering:
                if me < 0.576:
                    tem = tem*FLAGS.tem

            if test == True:
                ra += me
                move_list.append(move_dis.item())
                energy_diff_list.append((out_x - out_xnew).mean().item())
                q_list.append((log_x_xnew - log_xnew_x).mean().item())
                grad_list.append(grad.mean().item())
                list_me.append(me)

            if FLAGS.dataset in ("cifar10", "cats", "svhn"):
                n = 128
            elif FLAGS.dataset == "mnist":
                n = 128

            im_neg_kl = im_neg_orig[:n]
            if sample:
                pass
            else:
                energy = model.forward(im_neg_kl, label)
                im_grad = torch.autograd.grad([energy.sum()], [im_neg_kl], create_graph=True)[0]

            im_neg_kl = im_neg_kl - FLAGS.step_lr * im_grad[:n]
            im_neg_kl = torch.clamp(im_neg_kl, 0, 1)
        else:

            im_neg_orig = im_neg
            log_xnew_x, log_x_xnew, out_x, out_xnew, neg_new_img, grad = calculate_mala(model, im_neg, label, im_noise, FLAGS.step_lr)
            log_alpha = out_x - out_xnew + log_x_xnew/FLAGS.tem - log_xnew_x/FLAGS.tem

            alpha = torch.exp(torch.clamp_max(log_alpha, 0))
            mask = torch.rand(im_neg.shape[0], device=alpha.device)
            mask.unsqueeze_(dim=-1)
            a = mask < alpha

            while len(a.shape) < len(im_neg.shape):
                a.unsqueeze_(dim=-1)
            
            me = torch.mean(a.float()).float().item()

            result = torch.where(a, neg_new_img, im_neg)
            im_neg = result

            square = ((im_neg-im_neg_orig) ** 1).sum(dim=tuple(range(1, (im_neg-im_neg_orig).ndim)))
            move_dis = (square ** (1)).mean()

            if FLAGS.tempering:
                if me < 0.576:
                    tem = tem*FLAGS.tem

            if test == True:
                ra += me
                move_list.append(move_dis.item())
                energy_diff_list.append((out_x - out_xnew).mean().item())
                q_list.append((log_x_xnew - log_xnew_x).mean().item())
                grad_list.append(grad.mean().item())
                list_me.append(me)

        im_neg = im_neg.detach()

        if sample:
            im_negs_samples.append(im_neg)

        im_neg = torch.clamp(im_neg, 0, 1)
    #print(list_me)

    if test == True:
            
            sample_method.append(ra/num_steps)
            
            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,energy_diff_list)        
            plt.xlabel('Steps in chain')
            plt.ylabel('Energy difference')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"mala_Energy difference")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,list_me)     
            plt.xlabel('Steps in chain')
            plt.ylabel('AC-ratio')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"mala_Accept")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,move_list)   
            plt.xlabel('Steps in chain')
            plt.ylabel('Transition Distance')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"mala_Distance")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,q_list)
            plt.xlabel('Steps in chain')
            plt.ylabel('q(X|X`) Difference')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"mala_QDifference")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,grad_list)
            plt.xlabel('Steps in chain')
            plt.ylabel('Gradient')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+ "mala_Gradient_energy")
            plt.close(0)

    if sample:
        return im_neg, im_neg_kl, im_negs_samples, np.abs(im_grad.detach().cpu().numpy()).mean()
    else:
        return im_neg, im_neg_kl, np.abs(im_grad.detach().cpu().numpy()).mean()

"""My contribution3:"""

def gen_psgld_image(label, FLAGS, model, im_neg, num_steps, sample=False, test = False, Lambda = 1):
    Lambda = FLAGS.Lambda

    im_noise = torch.randn_like(im_neg).detach()

    im_negs_samples = []

    square_avg = torch.zeros_like(im_neg)
    #neg_image.requires_grad = True
    l_samples = []

    list_ave = []
    energy_diff_list = []
    move_list = []
    grad_list = []

    all_sample = []

    x_grad = 0
    avg_ = 0

    for i in range(num_steps):
        im_noise.normal_()

        if FLAGS.anneal:
            im_neg = im_neg + 0.001 * (num_steps - i - 1) / num_steps * im_noise
        else:
            im_neg = im_neg + 0.001 * im_noise

        im_neg.requires_grad_(requires_grad=True)
        
        energy = model.forward(im_neg,label)
        grad_1 = torch.autograd.grad([energy.sum()], [im_neg])[0]
        if i == num_steps - 1:
            im_neg_orig = im_neg

            beta = 0.9
            square_avg = square_avg * beta + grad_1*grad_1 * (1-beta)
            avg = 1*(square_avg.sqrt().add_(Lambda))
            #print(avg.shape)
            avg_me = torch.mean(avg.float()).float()
      
            #noise = torch.normal(mean=0,std=avg)
            im_neg = im_neg - FLAGS.step_lr / avg * grad_1

            square = ((im_neg-im_neg_orig) ** 1).sum(dim=tuple(range(1, (im_neg-im_neg_orig).ndim)))
            move_dis = (square ** (1)).mean()
            
            if test == True:
                avg_ += avg_me
                move_list.append(move_dis.item())
                grad_list.append(grad_1.mean().item())
                list_ave.append(avg_me)
                
            if FLAGS.dataset in ("cifar10", "cats", "svhn"):
                n = 128
            elif FLAGS.dataset == "mnist":
                n = 128

            im_neg_kl = im_neg_orig[:n]
            if sample:
                pass
            else:
                energy = model.forward(im_neg_kl, label)
                im_grad = torch.autograd.grad([energy.sum()], [im_neg_kl], create_graph=True)[0]

            im_neg_kl = im_neg_kl - FLAGS.step_lr * im_grad[:n]
            im_neg_kl = torch.clamp(im_neg_kl, 0, 1)
        else:
            im_neg_orig = im_neg
            beta = 0.9
            
            square_avg = square_avg * beta + grad_1*grad_1 * (1-beta)
            avg = 1*(square_avg.sqrt().add_(Lambda))
            #print(avg.shape)
            avg_me = torch.mean(avg.float()).float().item()
      
            #noise = torch.normal(mean=0,std=avg)

            im_neg = im_neg - FLAGS.step_lr / avg * grad_1
            
            square = ((im_neg-im_neg_orig) ** 1).sum(dim=tuple(range(1, (im_neg-im_neg_orig).ndim)))
            move_dis = (square ** (1)).mean()

            if test == True:
                avg_ += avg_me
                move_list.append(move_dis.item())
                grad_list.append(grad_1.mean().item())
                list_ave.append(avg_me)

        im_neg = im_neg.detach()

        if sample:
            im_negs_samples.append(im_neg)

        im_neg = torch.clamp(im_neg, 0, 1)

    if test == True:
            sample_method.append(avg_/num_steps)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,list_ave)     
            plt.xlabel('Steps in chain')
            plt.ylabel('1/G')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"psgld_ave")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,move_list)   
            plt.xlabel('Steps in chain')
            plt.ylabel('Transition Distance')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+"psgld_Distance")
            plt.close(0)

            plt.figure(figsize = (10,10))
            x = range(num_steps)
            plt.plot(x,grad_list)
            plt.xlabel('Steps in chain')
            plt.ylabel('Gradient')
            plt.grid()
            plt.savefig(FLAGS.save + str(FLAGS.itr)+ "psgld_Gradient_energy")
            plt.close(0)

    if sample:
        return im_neg, im_neg_kl, im_negs_samples, np.abs(im_grad.detach().cpu().numpy()).mean()
    else:
        return im_neg, im_neg_kl, np.abs(im_grad.detach().cpu().numpy()).mean()

def test(model, logger, dataloader):
    pass

def log_tensorboard(data):  
    writer.add_scalar("replay buffer length", data["length_replay_buffer"], data["iter"])
    writer.add_scalar("repel loss", data["loss_repel"], data["iter"])
    writer.add_scalar("batch loss", data["loss"], data["iter"])
    writer.add_scalar("average loss", data["avg_loss"], data["iter"])
    writer.add_scalar("KL mean loss", data["kl_mean"], data["iter"])
    
    writer.add_scalar("FID", data["fid"], data["iter"])
    writer.add_scalar("IS mean", data["is_mean"], data["iter"])
    writer.add_scalar("IS std", data["is_std"], data["iter"])
    writer.add_scalar("SSIM", data["ssim"], data["iter"])

    writer.add_scalar("positive energy mean", data["e_pos"], data["iter"])
    writer.add_scalar("positive energy std", data["e_pos_std"], data["iter"])

    writer.add_scalar("negative energy mean", data["e_neg"], data["iter"])
    writer.add_scalar("negative energy std", data["e_neg_std"], data["iter"])

    writer.add_scalar("energy different", data["e_diff"], data["iter"])
    writer.add_scalar("x gradient", data["x_grad"], data["iter"])

    writer.add_images("positive examples", data["positive_samples"], data["iter"])
    writer.add_images("negative examples", data["negative_samples"], data["iter"])

    writer.add_scalar("sample method", data["sample_method"], data["iter"])

from torchvision import datasets, transforms, utils
def train(model, optimizer, dataloader,logdir, resume_iter, FLAGS, best_inception, test_dataset, replay):
    if replay is not None:
      replay_buffer = replay
    else:
      if FLAGS.replay_batch:
        if FLAGS.reservoir:
            replay_buffer = ReservoirBuffer(FLAGS.buffer_size, FLAGS.transform, FLAGS.dataset)
        else:
            replay_buffer = ReplayBuffer(FLAGS.buffer_size, FLAGS.transform, FLAGS.dataset)

    dist_sinkhorn = SamplesLoss('sinkhorn')
    itr = resume_iter
    im_neg = None
    gd_steps = 1

    optimizer.zero_grad()

    num_steps = FLAGS.num_steps

    for epoch in range(FLAGS.epoch_num):
        print("epoch : ", epoch)
        tock = time.time()
        average_loss = 0.0

        save_log = osp.join(logdir, str(epoch))
        flags['save'] = save_log

        if not osp.exists(save_log):
            os.makedirs(save_log)

        for data_corrupt, data, label in tqdm(dataloader):
            FLAGS.itr = itr
            label = label.float().to(FLAGS.gpu, non_blocking=True)
            data = data.permute(0, 3, 1, 2).float().contiguous()
            #print(data.shape)
            
            # Generate samples to evaluate inception score
            if itr % FLAGS.save_interval == 0:
                if FLAGS.dataset in ("cifar10", "svhn", "cats"):
                    data_corrupt = torch.Tensor(np.random.uniform(0.0, 1.0, (128, 32, 32, 3)))
                    repeat = 128 // FLAGS.batch_size + 1
                    label = torch.cat([label] * repeat, axis=0)
                    label = label[:128]
                elif FLAGS.dataset == "mnist":
                    data_corrupt = torch.Tensor(np.random.uniform(0.0, 1.0, (128, 28, 28, 1)))
                    label = label[:128]
                    data_corrupt = data_corrupt[:label.shape[0]]
                else:
                    assert False
            
            data_corrupt = torch.Tensor(data_corrupt.float()).permute(0, 3, 1, 2).float().contiguous()
            data = data.to(FLAGS.gpu, non_blocking=True)
            data_corrupt = data_corrupt.to(FLAGS.gpu, non_blocking=True)
            
            if FLAGS.replay_batch and len(replay_buffer) >= FLAGS.batch_size:
                replay_batch, idxs = replay_buffer.sample(data_corrupt.size(0))
                replay_batch = decompress_x_mod(replay_batch)
                replay_mask = (
                    np.random.uniform(
                        0,
                        1,
                        data_corrupt.size(0)) > 0.001)
                data_corrupt[replay_mask] = torch.Tensor(replay_batch[replay_mask]).to(FLAGS.gpu, non_blocking=True)
            else:
                idxs = None

            if FLAGS.sampler == "psgld":
                if itr % FLAGS.save_interval == 0:
                    im_neg, im_neg_kl, x_grad = gen_psgld_image(label, FLAGS, model, data_corrupt, num_steps, sample=False, test = True)                                                           
                else:
                    im_neg, im_neg_kl, x_grad = gen_psgld_image(label, FLAGS, model, data_corrupt, num_steps)
            elif FLAGS.sampler == "mala":
                if FLAGS.initial:
                    if itr < FLAGS.initial_batch:
                        if itr % FLAGS.save_interval == 0:
                            im_neg, im_neg_kl, x_grad = gen_sgld_image(label, FLAGS, model, data_corrupt, num_steps, sample=False, test = True)
                        else:
                            im_neg, im_neg_kl, x_grad = gen_sgld_image(label, FLAGS, model, data_corrupt, num_steps)
                    else:
                        if itr % FLAGS.save_interval == 0:
                            im_neg, im_neg_kl, x_grad = gen_mala_image(label, FLAGS, model, data_corrupt, num_steps, sample=False, test = True)
                        else:
                            im_neg, im_neg_kl, x_grad = gen_mala_image(label, FLAGS, model, data_corrupt, num_steps)
                else:
                    if itr % FLAGS.save_interval == 0:
                        im_neg, im_neg_kl, x_grad = gen_mala_image(label, FLAGS, model, data_corrupt, num_steps, sample=False, test = True)
                    else:
                        im_neg, im_neg_kl, x_grad = gen_mala_image(label, FLAGS, model, data_corrupt, num_steps)
            elif FLAGS.sampler == "sgld":
                if itr % FLAGS.save_interval == 0:
                    im_neg, im_neg_kl, x_grad = gen_sgld_image(label, FLAGS, model, data_corrupt, num_steps, sample=False, test = True)
                else:
                    im_neg, im_neg_kl, x_grad = gen_sgld_image(label, FLAGS, model, data_corrupt, num_steps)
           
            else:
                assert False
            

            test_dataloader = DataLoader(test_dataset, num_workers=FLAGS.data_workers, batch_size=128, shuffle=True)

            data_test = 0


            # data_corrupt = None
            energy_pos = model.forward(data, label[:data.size(0)])
            energy_neg = model.forward(im_neg, label)
            
            if FLAGS.replay_batch and (im_neg is not None):
                replay_buffer.add(compress_x_mod(im_neg.detach().cpu().numpy()))

            loss = energy_pos.mean() - energy_neg.mean() 
            loss = loss  + (torch.pow(energy_pos, 2).mean() + torch.pow(energy_neg, 2).mean())

            if FLAGS.kl:
                model.requires_grad_(False)
                loss_kl = model.forward(im_neg_kl, label)
                model.requires_grad_(True)
                loss = loss + FLAGS.kl_coeff * loss_kl.mean()

                if FLAGS.repel_im:
                    start = timeit.timeit()
                    bs = im_neg_kl.size(0)

                    im_flat = torch.clamp(im_neg_kl.view(bs, -1), 0, 1)

                    if FLAGS.dataset in ("cifar10", "cats", "svhn"):
                        if len(replay_buffer) > 1000:
                            compare_batch, idxs = replay_buffer.sample(100, no_transform=False)
                            compare_batch = decompress_x_mod(compare_batch)
                            compare_batch = torch.Tensor(compare_batch).to(FLAGS.gpu, non_blocking=True)
                            compare_flat = compare_batch.view(100, -1)

                            if FLAGS.entropy == 'kl':
                                dist_matrix = torch.norm(im_flat[:, None, :] - compare_flat[None, :, :], p=2, dim=-1)
                                loss_repel = torch.log(dist_matrix.min(dim=1)[0]).mean()
                                # loss_repel = kldiv(im_flat, compare_flat)
                                loss = loss - 0.3 * loss_repel
                            elif FLAGS.entropy == 'sinkhorn':
                                dist_matrix = dist_sinkhorn(im_flat, compare_flat)
                                loss_repel = torch.log(dist_matrix).sum()
                                loss = loss - 0.03 * loss_repel
                            else:
                                assert False                     
                        else:
                            loss_repel = torch.zeros(1)
                        
                    else:
                        if len(replay_buffer) > 1000:
                            compare_batch, idxs = replay_buffer.sample(100, no_transform=False, downsample=True)
                            compare_batch = decompress_x_mod(compare_batch)
                            compare_batch = torch.Tensor(compare_batch).to(FLAGS.gpu, non_blocking=True)
                            compare_flat = compare_batch.view(100, -1)
                            
                            if FLAGS.entropy == 'kl':
                                dist_matrix = torch.norm(im_flat[:, None, :] - compare_flat[None, :, :], p=2, dim=-1)
                                loss_repel = torch.log(dist_matrix.min(dim=1)[0]).mean()
                                # loss_repel = kldiv(im_flat, compare_flat)
                            elif FLAGS.entropy == 'sinkhorn':
                                dist_matrix = dist_sinkhorn(im_flat, compare_flat)
                                loss_repel = torch.log(dist_matrix).sum()
                            else:
                                assert False
                        else:
                            loss_repel = torch.zeros(1).to(FLAGS.gpu, non_blocking=True)

                        if FLAGS.entropy == 'kl':
                            loss = loss - 0.3 * loss_repel  
                        elif FLAGS.entropy == 'sinkhorn':
                            loss = loss - 0.03 * loss_repel
                        else:
                            assert False

                    end = timeit.timeit()
                else:
                    loss_repel = torch.zeros(1)

            else:
                loss_kl = torch.zeros(1)
                loss_repel = torch.zeros(1)

            if FLAGS.log_grad and len(replay_buffer) > 1000:
                loss_kl = loss_kl - 0.1 * loss_repel
                loss_kl = loss_kl.mean()
                loss_ml = energy_pos.mean() - energy_neg.mean()

                loss_ml.backward(retain_graph=True)
                ele = []

                for param in model.parameters():
                    if param.grad is not None:
                        ele.append(torch.norm(param.grad.data))

                ele = torch.stack(ele, dim=0)
                ml_grad = torch.mean(ele)
                model.zero_grad()

                loss_kl.backward(retain_graph=True) 
                ele = []

                for param in model.parameters():
                    if param.grad is not None:
                        ele.append(torch.norm(param.grad.data))

                ele = torch.stack(ele, dim=0)
                kl_grad = torch.mean(ele)
                model.zero_grad()

            else:
                ml_grad = None
                kl_grad = None

            loss.backward()

            clip_grad_norm_(model.parameters(), 0.5)

            optimizer.step()
            optimizer.zero_grad()

            if torch.isnan(energy_pos.mean()):
                assert False

            if torch.abs(energy_pos.mean()) > 10.0:
                assert False
            
            average_loss += (loss - average_loss) / (itr + 1)
            if itr % FLAGS.log_interval == 0:

                for data_corrupt, data1, label in test_dataloader:
                    data1 = data1.permute(0, 3, 1, 2).float().contiguous()

                    data_test = data1
                    utils.save_image(
                        data1.detach().to('cpu'),
                        f'{save_log}/ori{str(itr).zfill(5)}.png',
                        nrow=16,
                        normalize=True,
                        range=(0, 1),)
                    break

                utils.save_image(
                    im_neg.detach().to('cpu'),
                    f'{save_log}/neg{str(itr).zfill(5)}.png',
                    nrow=16,
                    normalize=True,
                    range=(0, 1),)


                tick = time.time()

                kvs = {}
                kvs['e_pos'] = energy_pos.mean().item()
                kvs['e_pos_std'] = energy_pos.std().item()
                kvs['e_neg'] = energy_neg.mean().item()
                kvs['e_neg_std'] = energy_neg.std().item()


                kvs['kl_mean'] = loss_kl.mean().item()
                kvs['loss_repel'] = loss_repel.mean().item()
                kvs['loss'] = loss
                kvs['avg_loss'] = average_loss
                kvs['e_diff'] = kvs['e_pos'] - kvs['e_neg']
                # kvs['x_grad'] = np.abs(x_grad.detach().cpu().numpy()).mean()
                kvs['x_grad'] = x_grad
                kvs['iter'] = itr

                # kvs['hmc_loss'] = hmc_loss.item()
                kvs['num_steps'] = num_steps
                # kvs['t_diff'] = tick - tock
                kvs['positive_samples'] = data.detach()
                kvs['negative_samples'] = im_neg.detach()
                kvs['sample_method'] = sample_method[-1]

                real = data_test.detach()
                fake = im_neg.detach()
                
                if real.shape[1] == 1:
                    # print("channel 1")
                    real = torch.cat((real, real, real), dim=1)
                    fake = torch.cat((fake, fake, fake), dim=1)
                real = torch.from_numpy(rescale_im(real.cpu().numpy())).to(FLAGS.gpu, non_blocking=True)
                fake = torch.from_numpy(rescale_im(fake.cpu().numpy())).to(FLAGS.gpu, non_blocking=True)
                # print("real shape = ", real.shape)
                # print("campute IS")
                inception.update(fake)
                inception_mean, inception_std = inception.compute()
                # print("campute FID")
                fid.update(real, real=True)
                fid.update(fake, real=False)
                fid_val = fid.compute()
                real = None
                fake = None
                ssim_value = 0
                kvs['fid'] = fid_val.item()
                print(kvs['fid'])

                kvs['is_mean'] = inception_mean.item()
                kvs['is_std'] = inception_std.item()
                kvs['ssim'] = ssim_value

                if FLAGS.replay_batch:
                    kvs['length_replay_buffer'] = len(replay_buffer)

                log_tensorboard(kvs)
                tock = tick

            if itr % FLAGS.save_interval == 0 and (FLAGS.save_interval != 0):
                model_path = osp.join(logdir, "model_{}.pth".format(itr))
                ckpt = {'optimizer_state_dict': optimizer.state_dict(),
                     'FLAGS': FLAGS, 
                     'best_inception': best_inception,
                     'replay': replay_buffer}

                for i in range(FLAGS.ensembles):
                    ckpt['model_state_dict_{}'.format(i)] = model.state_dict()
                    # ckpt['ema_model_state_dict_{}'.format(i)] = model.state_dict()

                torch.save(ckpt, model_path)


            itr += 1

def main_single(FLAGS):
    print("Values of args: ", FLAGS)

    if FLAGS.dataset == "cifar10":
        train_dataset = Cifar10(FLAGS)
        test_dataset = Cifar10(FLAGS, train=False, augment=False)
    elif FLAGS.dataset == "cats":
        train_dataset = Cats()
        test_dataset = Cats()
    elif FLAGS.dataset == "mnist":
        train_dataset = Mnist(train=True)
        test_dataset = Mnist(train=False)
    elif FLAGS.dataset == "svhn":
        train_dataset = Svhn(train=True)
        test_dataset = Svhn(train=False)
    else:
        assert False

    train_dataloader = DataLoader(train_dataset, num_workers=FLAGS.data_workers, batch_size=FLAGS.batch_size, shuffle=True, drop_last=True)

    logdir = osp.join(sample_dir, FLAGS.exp, FLAGS.dataset)

    best_inception = 0.0
    if FLAGS.resume_iter != 0:
        FLAGS_OLD = FLAGS
        model_path = osp.join(logdir, "model_{}.pth".format(FLAGS.resume_iter))
        checkpoint = torch.load(model_path)
        best_inception = checkpoint['best_inception']
        FLAGS = checkpoint['FLAGS']

        FLAGS.resume_iter = FLAGS_OLD.resume_iter
        FLAGS_OLD = None

    if FLAGS.dataset in ("cifar10", "cats", "svhn"):
        model_fn = ResNetModel
    elif FLAGS.dataset == "mnist":
        model_fn = MNISTModel
    else:
        assert False

    model = model_fn(FLAGS).train()
    # models_ema = model_fn(FLAGS).train()

    if FLAGS.cuda:
        model = model.to(FLAGS.gpu)

    optimizer = Adam(model.parameters(), lr=FLAGS.lr, betas=(0.0, 0.9), eps=1e-8)

    it = FLAGS.resume_iter

    if not osp.exists(logdir):
        os.makedirs(logdir)

    checkpoint = None
    replay = None
    if FLAGS.resume_iter != 0:
        print("FLAGS.resume_iter:",FLAGS.resume_iter)
        model_path = osp.join(logdir, "model_{}.pth".format(FLAGS.resume_iter))
        checkpoint = torch.load(model_path)
        replay = checkpoint['replay']
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

        for i in range(FLAGS.ensembles):
            model.load_state_dict(checkpoint['model_state_dict_{}'.format(i)]) 

    print("New Values of args: ", FLAGS)

    pytorch_total_params = sum([p.numel() for p in model.parameters() if p.requires_grad])
    print("Number of parameters for models", pytorch_total_params)

    train(model, optimizer, train_dataloader, logdir, FLAGS.resume_iter, FLAGS, best_inception, test_dataset, replay)

!kill 6006

tensorboard --logdir runs

main_single(flags)